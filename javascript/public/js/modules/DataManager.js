// =============================================
// Sync procedure - Processor
// =============================================
import EKThresholdDetector from "../Engbert_Kliegl_partial.js";

let faceLostReported = false;

function fixationConfusionBinding(samples, confusionWindow) {
    if (samples.x.length === 0) return [[], []];

    let [fixations, saccades] = detector.detect(samples);

    let any_confused = confusionWindow.some((state) => state === 'Confused');

    let lastConfusedFixation = 0;
    // Nested for loops for confusion/fixation binding
    if (any_confused && fixations.length !== 0) {
        for (const [i, state] of confusionWindow.entries()) {
            if (state === 'Confused') {
                let tConfusion = (i + 1) * inferInterval + samples.t[0];
                for (let fixation of fixations) {
                    if (fixation.contain(tConfusion)) {
                        fixation.incConfusionCount()
                        lastConfusedFixation = fixations.indexOf(fixation);
                    } else if (fixation.start >= tConfusion) {
                        break;
                    }
                }
            }
        }
    }

    // fixations.forEach((fixation, i) => console.log(
    // `#${i+1}:${fixation.data.start} - ${fixation.data.end}, contains ${fixation.data.confusionCount}`
    // ));

    // if (fixations.length > 0 && fixations[lastConfusedFixation].confusionCount > 0) {
    //     console.log('Draw prompt box!')
    //     showPromptBox(fixations[lastConfusedFixation], patch_w, patch_h);
    // } else {
    //     showPromptBox(fixations[lastConfusedFixation], -1, -1); // -1 means to delete
    // }

    return [fixations, saccades];
}

function inattentionFromFace(confusionWindow) {
    let all_noface = confusionWindow.every((state) => state === 'N/A');
    let inattentionCount = 0;

    if (all_noface) {
        // Face is lost during past 5s, increase inattention count
        ++inattentionCount;
        if (!faceLostReported) {
            // Do not keep notifying the student, just once.
            faceLostReported = true;
            // new Audio('/media/audio/facelost.mp3').play().catch(err => console.log(err));
        }
    } else if (faceLostReported) {
        // Face is back, reset flag.
        faceLostReported = false;
    }

    return inattentionCount
}

/**
 * The DataManager abstracts all dataGenerators.
 * It is the publisher for dataGenerators defined in DataGenerator.js
 * @constructor
 */
class DataManager {
    constructor() {
        this.observerList = [];
    }

    /**
     * Subscribes a subscriber/DataGenerator to the publisher/DataManager
     * @param subscriber - An instance of DataGenerator with interface generateData()
     * @returns {number} - The index will be used for unsubscribe
     */
    subscribe(subscriber) {
        this.observerList.push(subscriber);
        return this.observerList.length - 1 // this index will be used for unsubscribe
    }

    /**
     * Unsubscribes a subscriber/DataGenerator with the publisher/DataManager
     * @param {number} index - The index of the subscriber in the list.
     * @returns {number} - Always returns -1, an invalid index.
     */
    unsubscribe(index) {
        if (!index && index > -1) {
            // index exists (not undefined/null) and have previously subscribed
            this.observerList.splice(index, 1);
        }
        return -1
    }

    /**
     * Notifies all subscribers to generate data. Not all DataGenerators listen to this.
     * @returns {Promise<unknown[]>}
     */
    notifySubscribers() {
        return Promise.all(
            this.observerList.map(observer => observer.generateData())
        )
    }

    /**
     * The getter which returns all the data generated by DataGenerators.
     * @abstract
     */
    get data() {throw new Error("Getter data() is not implemented.");}
}

/**
 * @typedef Confusion
 * @type {object}
 * @param {number} slideId - The identifier of the slide.
 * @param {number} aoiId - The identifier of the AoI.
 * @param {number} timestamp - The timestamp of the reported confusion.
 */

/**
 * @typedef StudentData
 * @type {object}
 * @property {number|string} stuNum - The student number.
 * @property {number|string} lectureId - The ID of current lecture.
 * @property {number|string} groupId - The ID of student experiment group.
 * @property {object} gaze_samples - The gaze points in 0-1 scale. A dictionary containing fields: x, y, timestamp.
 * @property {object} raw_samples - The gaze points in pixel unit.
 * A dictionary containing fields: x, y, timestamp, clientWidth, clientHeight.
 * @property {number[]} thresholds - The velocity thresholds. An array [vx_threshold, vy_threshold]
 * @property {Confusion[]} confusion - A list of confusions reported by the user.
 * @property {number} inattention -  The number of detected inattention.
 */

/**
 * @typedef WorkshopStudentData
 * @type {object}
 * @property {number|string} stuNum - The student number.
 * @property {number|string} lectureId - The ID of current (workshop) lecture.
 * @property {number|string} groupId - The ID of student experiment group.
 * @property {object} raw_samples - The gaze points in pixel unit.
 * A dictionary containing fields: x, y, timestamp, clientWidth, clientHeight.
 * @property {Confusion[]} confusion - A list of confusions reported by the user.
 * @property {number} inattention -  The number of detected inattention.
 */

/**
 * @typedef TeacherData
 * @type {object}
 * @property {number} slide_id - The sequential number of slide screenshot.
 * @property {number} screenshot - The screenshot itself. Encoded in base64.
 * todo: check is detector is working as expected
 */

class StudentDataManager extends DataManager {
    constructor() {
        super();

        this.detector = new EKThresholdDetector();
        // Set all properties to initial state.
        this.reset();
    }

    /**
     * Compose the data a student should post.
     * @return {StudentData} - The composed student data. Some other fields are added at {@link SyncProcedure} post() function.
     */
    get data() {
        // let data = this.process(samples);
        // this.reset();
        // return data

        const maxH = document.documentElement.clientHeight,
            maxW = document.documentElement.clientWidth;

        let samples = {
            x: this.gazeXWindow.map(x => x/maxW),
            y: this.gazeYWindow.map(y => y/maxH),
            t: this.gazeTimestampWindow,
        };
        // TODO: Filtering will happen inside the detector?
        let thresholds = this.detector.getVelocityThreshold(
            samples, {lambda: 3}
        )
        let d = {
            stuNum: userInfo['number'],
            lectureId: lectureInfo.lecture.lectureId,
            groupId: userInfo["group"],
            /**
             * Normalized to 0-1 scale. See {@link https://mathjs.org/examples/matrices.js.html}.
             */
            gaze_samples : {
                x: samples.x.valueOf(),
                y: samples.y.valueOf(),
                timestamp: samples.t.valueOf(),
            },
            /**
             * Gaze points in the pixel unit.
             */
            raw_samples : {
                x: this.gazeXWindow,
                y: this.gazeYWindow,
                timestamp: this.gazeTimestampWindow,
                clientWidth: maxW,
                clientHeight: maxH,
            },
            thresholds,
            confusion: this.reportedConfusionWindow,
            /**
             * Both inattention detected from 1) visibility change and 2) face lost are summed.
             */
            inattention: this.inattentionCount + this.faceLostCount,
            /**
             * A list of mouse events. Including clicks, and movement.
             */
            mouse_events: this.mouseEventWindow,
        }
        this.reset()
        return d
    }

    /**
     * Add gaze point data to the data manager.
     * @param {Object} gazeData - An object containing the following 4 fields:
     * @param {number} gazeData.state - 0: valid gaze data; -1 : face tracking lost, 1 : gaze uncalibrated
     * @param {number} gazeData.docX - gaze x in document coordinates
     * @param {number} gazeData.docY - gaze y in document coordinates
     * @param {number} gazeData.time - timestamp
     */
    addGazeData(gazeData) {
        switch (gazeData.state) {
            case 0:
                // 0: valid gaze data
                // Visualize gaze with DOM div element #gaze
                this.gazeXWindow.push(gazeData.docX);
                this.gazeYWindow.push(gazeData.docY);
                this.gazeTimestampWindow.push(gazeData.time);
                break;
            case -1:
                // -1 : face tracking lost
                // Hide gaze visualization
                // The value of gazeX/gazeY stays same as last valid gaze
                this.faceLostCount++;
                break;
            case 1:
                // 1 : gaze uncalibrated
                // Hide gaze visualization
                // The value of gazeX/gazeY stays same as last valid gaze
            default:
                break;
        }
    }

    /**
     * Add facial expression data to the data manager.
     * @param {string} facialExpData - One in ['N/A', "Confused", "Neutral"], indicating the state.
     */
    addFacialExpData(facialExpData) {
        this.facialExpressionWindow.push(facialExpData);
        if (facialExpData === 'N/A') this.incFaceLostCount();
    }

    /**
     * Add self-reported confusion to the data manager.
     * @param {number} slideId - The identifier of the slide.
     * @param {number} aoiId - The identifier of the AoI.
     * @param {number} timestamp - The timestamp of the reported confusion.
     */
    addReportedConfusion(slideId, aoiId, timestamp) {
        this.reportedConfusionWindow.push({
            slide_id: slideId,
            aoi_id: aoiId,
            timestamp
        })
    }

    /**
     * Add mouse event and movement data to the data manager. Each record is:
     * [timestamp, event, mouse_x, mouse_y, slide_id, aoi_id]
     * @param {number} xCoord The x coordinate of the mouse event.
     * @param {number} yCoord The y coordinate of the mouse event.
     * @param {string} event A string representing the name of mouse event.
     * @param {string} aoiId The soi_id w.r.t. mouse clicks. Can be NaN if the clicks are outside AoIs.
     */
    addMouseEvent(xCoord, yCoord, event, aoiId) {
        this.mouseEventWindow.push([
            Date.now(), event, xCoord, yCoord, slideId, aoiId
        ])
    }

    incFaceLostCount = ()=>{this.faceLostCount++}
    incInattentionCount = ()=>{this.inattentionCount++}

    process(gazeSamples) {
        let [fixations, saccades] = fixationConfusionBinding(gazeSamples, this.facialExpressionWindow);
        this.inattentionCount += inattentionFromFace(this.facialExpressionWindow);

        return {
            stuNum: userInfo['number'],
            fixations: fixations.length === 0 ? fixations : fixations.map(fixation => fixation.data),
            saccades: saccades,
            cognitive: {
                confusion: this.facialExpressionWindow,
                inattention: this.inattentionCount,
            }
        }
    }

    reset() {
        // Managing the gaze information
        this.gazeXWindow = [];
        this.gazeYWindow = [];
        this.gazeTimestampWindow = [];
        // Managing the facial expression information
        this.facialExpressionWindow = [];
        this.faceLostCount = 0; // used by gaze info as well
        this.inattentionCount = 0;
        // Managing the confusion reported from AoI
        this.reportedConfusionWindow = [];
        // Managing the mouse movement data
        this.mouseEventWindow = [];
    }
}

class TeacherDataManager extends DataManager {
    constructor() {
        super();
        this.slideId = 0;
        this.screenshot = undefined;
        this.padding = {};
        this.defaultPadding = {
            top:0,
            availableHeight: _jitsi.getIFrame().getBoundingClientRect().height,
            availableWidth: _jitsi.getIFrame().getBoundingClientRect().width,
        };
        this.screenshotHash = "";
    }

    /**
     * Compose the data a teacher should post.
     * @return {TeacherData} - The composed teacher data. Some other fields are added at {@link SyncProcedure} post() function.
     */
    get data() {
        return {
            slide_id : this.slideId,
            screenshot: this.screenshot,
            padding: this.padding.top ? this.padding : this.defaultPadding,
        }
    }

    async addScreenshot(screenshot, padding = {}) {
        // Comparing the hash of screenshot is managed in ScreenCapturer.
        // The global slideId is managed in ScreenCapturer as well.
        this.screenshot = screenshot;
        this.slideId += 1;

        // we also need shape of:
        // top coordinate of iframe; left/right or top/bottom padding for largeVideo in Jitsi
        // to correctly padding on the server side.
        this.padding = padding;
    }
}

class WorkshopDataManager extends DataManager {
    constructor() {
        super();

        this.detector = new EKThresholdDetector();
        // Set all properties to initial state.
        this.reset();
    }


    /**
     * Compose the data a student in workshop should post.
     * @return {WorkshopStudentData} The composed student data. Some other fields are added at {@link SyncProcedure} post() function.
     */
    get data() {
        const maxH = document.documentElement.clientHeight,
            maxW = document.documentElement.clientWidth;

        let d = {
            stuNum: userInfo['number'],
            lectureId: localStorage.getItem("talkId"),
            groupId: userInfo["group"],
            raw_samples : {
                x: this.gazeXWindow,
                y: this.gazeYWindow,
                timestamp: this.gazeTimestampWindow,
                clientWidth: maxW,
                clientHeight: maxH,
            },
            facialExpression: this.facialExpressionWindow,
            confusion: this.reportedConfusionWindow,
            inattention: this.inattentionWindow,
            mouse_events: this.mouseEventWindow,
        }
        this.reset()
        return d
    }

    /**
     * Add facial expression data to the data manager.
     * @param {string} facialExpData A base-64 string captured from the webcam.
     */
    addFacialExpData(facialExpData) {
        this.facialExpressionWindow.push([
            Date.now(), facialExpData
        ]);
    }

    /**
     * Add self-reported confusion to the data manager.
     * @param {number} x_coord - The x coordinate of the reported confusion.
     * @param {number} y_coord - The y coordinate of the reported confusion.
     */
    addReportedConfusion(x_coord, y_coord) {
        this.reportedConfusionWindow.push([
            Date.now(), x_coord, y_coord
        ])
    }

   /**
     * Add mouse event and movement data to the data manager. Each record is:
     * [timestamp, event, mouse_x, mouse_y]
     * @param {number} xCoord The x coordinate of the mouse event.
     * @param {number} yCoord The y coordinate of the mouse event.
     * @param {string} event A string representing the name of mouse event.
     */
    addMouseEvent(xCoord, yCoord, event) {
        this.mouseEventWindow.push([
            Date.now(), event, xCoord, yCoord
        ])
    }


   /**
     * Add mouse event and movement data to the data manager. Each record is:
     * [timestamp, reason]
     * @param {string} reason the reason for inattention
     */
    addInattention(reason) {
        this.inattentionWindow.push([
            Date.now(), reason
        ])
    }

    addGazeData(gazeData) {
        switch (gazeData.state) {
            case 0:
                // 0: valid gaze data
                // Visualize gaze with DOM div element #gaze
                this.gazeXWindow.push(gazeData.docX);
                this.gazeYWindow.push(gazeData.docY);
                this.gazeTimestampWindow.push(gazeData.time);
                break;
            case -1:
                // -1 : face tracking lost
                // Hide gaze visualization
                // The value of gazeX/gazeY stays same as last valid gaze
                this.addInattention("face-lost");
                break;
            case 1:
                // 1 : gaze uncalibrated
                // Hide gaze visualization
                // The value of gazeX/gazeY stays same as last valid gaze
            default:
                break;
        }
    }

    reset() {
        // Managing the gaze information
        this.gazeXWindow = [];
        this.gazeYWindow = [];
        this.gazeTimestampWindow = [];
        // Managing the facial expression information
        this.facialExpressionWindow = [];
        // Managing the inattention detected from face lost or switching tabs
        this.inattentionWindow = [];
        // Managing the confusion reported from clicking on the screen
        this.reportedConfusionWindow = [];
        // Managing the mouse movement data
        this.mouseEventWindow = [];
    }
}

export default function dataManagerFactory(role, lectureMode = "sync") {
    if (+role === TEACHER) {
        return new TeacherDataManager();
    } else {
        if (lectureMode === "sync") {
            return new StudentDataManager();
        } else {
            return new WorkshopDataManager();
        }
    }
}